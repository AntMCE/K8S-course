## Namespace that's stuck in the "terminating status":

1. Get all k8s resources that are stuck in the "terminating" stage in the Namespace and delete them.

Next, run the following commands:

```
kubectl get namespace NAMESPACE_NAME -o json > file.json
```
```
kubectl replace --raw "/api/v1/namespaces/NAMESPACE_NAME/finalize" -f ./file.json
```
After that, you should see that the Namespace can now be successfully deleted without sitting in the "Terminating" stage


## Get pod Events:
```
kubectl describe pod <pod-name> -n <namespace> | grep -A5 "Events:
```
## Pod failures (credit to Suman Chakraborty Senior Solution Engineer at VMware )

Pods can have startup and runtime errors.
 Startup errors include:

 âœ… ImagePullBackoff (among the 5 common failures )
 âœ… ImageInspectError
 âœ… ErrImagePull
 âœ… ErrImageNeverPull
 âœ… RegistryUnavailable
 âœ… InvalidImageName

 Runtime errors include:

 âœ… CrashLoopBackOff (among the 5 common failures )
 âœ… RunContainerError
 âœ… KillContainerError
 âœ… VerifyNonRootError
 âœ… RunInitContainerError
 âœ… CreatePodSandboxError
 âœ… ConfigPodSandboxError
 âœ… KillPodSandboxError
 âœ… SetupNetworkError
 âœ… TeardownNetworkError

â—ğ‘°ğ’ğ’‚ğ’ˆğ’†ğ‘·ğ’–ğ’ğ’ğ‘©ğ’‚ğ’„ğ’Œğ‘¶ğ’‡ğ’‡

âœ This error appears when k8s isn't able to retrieve the image for one of the hashtag#containers of the Pod.
There are three common culprits:

âœ… The image name is invalid
âœ… You specified a non-existing tag for the image.
âœ… The image that you're trying to retrieve belongs to a private registry and the cluster doesn't have credentials to access it.

The first two cases can be solved by correcting the image name and tag.
For the last, one should add the credentials to your private registry in a Secret and reference it in the Pods

â—ğ‘¹ğ’–ğ’ğ‘ªğ’ğ’ğ’•ğ’‚ğ’Šğ’ğ’†ğ’“ğ‘¬ğ’“ğ’“ğ’ğ’“

âœ The error appears when the container is unable to start before application
Common causes:

âœ… Mounting a not-existent volume such as ConfigMap or Secrets
âœ… Mounting a read-only volume as read-write

More detailed aspect can be found by describing the 'failed' pod

â—ğ‘ªğ’“ğ’‚ğ’”ğ’‰ğ‘³ğ’ğ’ğ’‘ğ‘©ğ’‚ğ’„ğ’Œğ‘¶ğ’‡ğ’‡

âœ If the container can't start, then Kubernetes shows the CrashLoopBackOff message as a status.
Usually, a container can't start when:

âœ… There's an error in the application that prevents it from starting.
âœ… You misconfigured the container.
âœ… The Liveness probe failed too many times.

â—ğ‘·ğ’ğ’…ğ’” ğ’Šğ’ ğ’‚ ğ‘·ğ’†ğ’ğ’…ğ’Šğ’ğ’ˆ ğ’”ğ’•ğ’‚ğ’•ğ’†

âœ Assuming that the scheduler component is running fine, here are the causes:

âœ… The cluster doesn't have enough resources such as CPU and memory to run the Pod.
âœ… The current Namespace has a ResourceQuota object and creating the Pod will make the Namespace go over the quota.
âœ… The Pod is bound to a Pending PersistentVolumeClaim.

The best option is to inspect the Events section in the "kubectl describe"

## 5 common k8s failures and how to fix them

ğŸ­) ğ—œğ—ºğ—®ğ—´ğ—²-ğ—½ğ˜‚ğ—¹ğ—¹ ğ—¯ğ—®ğ—°ğ—¸ ğ—¼ğ—³ğ—³ ~ Check for ğ™„ğ™¢ğ™–ğ™œğ™š ğ™¥ğ™ªğ™¡ğ™¡ ğ™¥ğ™¤ğ™¡ğ™ğ™˜ğ™® , ğ™¥ğ™šğ™§ğ™¢ğ™ğ™¨ğ™¨ğ™ğ™¤ğ™£ ğ™©ğ™¤ ğ™¥ğ™ªğ™¡ğ™¡ ğ™›ğ™§ğ™¤ğ™¢ ğ™§ğ™šğ™¥ğ™¤ğ™¨ğ™ğ™©ğ™¤ğ™§ğ™®,ğ™˜ğ™¤ğ™§ğ™§ğ™šğ™˜ğ™© ğ™ğ™¢ğ™–ğ™œğ™š ğ™£ğ™–ğ™¢ğ™š ğ™–ğ™¡ğ™¤ğ™£ğ™œ ğ™¬ğ™ğ™©ğ™ ğ™©ğ™–ğ™œ.

ğ™ğ™¨ğ™šğ™›ğ™ªğ™¡ ğ™˜ğ™¤ğ™¢ğ™¢ğ™–ğ™£ğ™™ğ™¨ 
```
 Kubectl describe po <podname>
 ```
 ```
 Kubectl get po <podname>
 ```
 ```
 Kubectl apply -f <deployment file name>
 ```


2) ğ˜¾ğ™§ğ™–ğ™¨ğ™-ğ™‡ğ™¤ğ™¤ğ™¥ ğ™—ğ™–ğ™˜ğ™  ğ™¤ğ™›ğ™›~ Check for ğ˜¾ğ™¤ğ™§ğ™§ğ™šğ™˜ğ™© ğ™ğ™¢ğ™–ğ™œğ™š ğ™£ğ™–ğ™¢ğ™š ğ™–ğ™¡ğ™¤ğ™£ğ™œ ğ™¬ğ™ğ™©ğ™ ğ™©ğ™–ğ™œ , ğ™šğ™£ğ™¤ğ™ªğ™œğ™ ğ™§ğ™šğ™¨ğ™¤ğ™ªğ™§ğ™˜ğ™š ğ™˜ğ™¤ğ™£ğ™¨ğ™©ğ™§ğ™–ğ™ğ™£ğ™©ğ™¨,ğ™¢ğ™ğ™¨ğ™˜ğ™¤ğ™£ğ™›ğ™ğ™œğ™ªğ™§ğ™–ğ™©ğ™ğ™¤ğ™£ ğ™¤ğ™› ğ™šğ™£ğ™«ğ™ğ™§ğ™¤ğ™£ğ™¢ğ™šğ™£ğ™© ğ™«ğ™–ğ™§ğ™ğ™–ğ™—ğ™¡ğ™šğ™¨ , ğ™–ğ™¥ğ™¥ğ™¡ğ™ğ™˜ğ™–ğ™©ğ™ğ™¤ğ™£ ğ™›ğ™–ğ™ğ™¡ğ™ªğ™§ğ™š ğ™—ğ™šğ™˜ğ™–ğ™ªğ™¨ğ™š ğ™¤ğ™› ( ğ™›ğ™–ğ™ğ™¡ ğ™©ğ™¤ ğ™—ğ™ªğ™ğ™¡ğ™™ ğ™Ÿğ™–ğ™§ ğ™›ğ™ğ™¡ğ™šğ™¨ , ğ™ğ™¨ğ™¨ğ™ªğ™šğ™¨ ğ™¬ğ™ğ™ğ™¡ğ™š ğ™—ğ™ªğ™ğ™¡ğ™™ğ™ğ™£ğ™œ ğ™™ğ™¤ğ™˜ğ™ ğ™šğ™§ ğ™ğ™¢ğ™–ğ™œğ™š.

ğ™ğ™¨ğ™šğ™›ğ™ªğ™¡ ğ™˜ğ™¤ğ™¢ğ™¢ğ™–ğ™£ğ™™ğ™¨ 
```
 Kubectl describe po <podname>
 ```
 ```
 Kubectl logs <podname>
 ```
 Also to check if enough resources are allocated (memory) 


3) ğ™ğ™–ğ™ğ™¡ğ™ªğ™§ğ™š ğ™¬ğ™ğ™©ğ™ ğ™€ğ™­ğ™ğ™© ğ™˜ğ™¤ğ™™ğ™š 1~ Check for ğ˜¼ğ™¥ğ™¥ğ™¡ğ™ğ™˜ğ™–ğ™©ğ™ğ™¤ğ™£ ğ™˜ğ™¤ğ™™ğ™š ğ™˜ğ™§ğ™–ğ™¨ğ™ğ™šğ™¨ , ğ™ğ™£ğ™˜ğ™¤ğ™§ğ™§ğ™šğ™˜ğ™© ğ™šğ™£ğ™«ğ™ğ™§ğ™¤ğ™£ğ™¢ğ™šğ™£ğ™© ğ™«ğ™–ğ™§ğ™ğ™–ğ™—ğ™¡ğ™šğ™¨, ğ™ğ™£ğ™¨ğ™ªğ™›ğ™›ğ™ğ™˜ğ™ğ™šğ™£ğ™© ğ™›ğ™ğ™¡ğ™š ğ™¥ğ™šğ™§ğ™¢ğ™ğ™¨ğ™¨ğ™ğ™¤ğ™£ğ™¨.


ğ™ğ™¨ğ™šğ™›ğ™ªğ™¡ ğ™˜ğ™¤ğ™¢ğ™¢ğ™–ğ™£ğ™™ğ™¨ 
```
 Kubectl logs <podname>
 ```
 ```
 Kubectl get po <podname>
 ```
 ```
 Kubectl apply -f <deployment file name>
 ```
Lookout for any exceptions in logs /missing variables at code level as well .


4) ğ™ğ™–ğ™ğ™¡ğ™ªğ™§ğ™š ğ™¬ğ™ğ™©ğ™ ğ™€ğ™­ğ™ğ™© ğ™˜ğ™¤ğ™™ğ™š125~ Check for ğ™ğ™£ğ™˜ğ™¤ğ™§ğ™§ğ™šğ™˜ğ™© ğ™›ğ™ğ™¡ğ™š ğ™¥ğ™šğ™§ğ™¢ğ™ğ™¨ğ™¨ğ™ğ™¤ğ™£ğ™¨ , ğ™šğ™­ğ™˜ğ™šğ™¥ğ™©ğ™ğ™¤ğ™£ğ™¨ ğ™™ğ™ªğ™§ğ™ğ™£ğ™œ ğ™—ğ™¤ğ™¤ğ™©ğ™ğ™£ğ™œ ğ™ªğ™¥ ğ™¤ğ™› ğ™¥ğ™¤ğ™™

ğ™ğ™¨ğ™šğ™›ğ™ªğ™¡ ğ™˜ğ™¤ğ™¢ğ™¢ğ™–ğ™£ğ™™ğ™¨  
```
 Kubectl logs <podname>
 ```
 ```
 Kubectl describe po <podname>
 ```

5) ğ™‹ğ™¤ğ™™/ğ™‰ğ™¤ğ™™ğ™š ğ™‰ğ™¤ğ™© ğ™ğ™šğ™–ğ™™ğ™® ~ Check for ğ™‰ğ™šğ™©ğ™¬ğ™¤ğ™§ğ™  ğ˜¾ğ™¤ğ™£ğ™£ğ™šğ™˜ğ™©ğ™ğ™«ğ™ğ™©ğ™® , ğ™šğ™£ğ™¤ğ™ªğ™œğ™ ğ™§ğ™šğ™¨ğ™¤ğ™ªğ™§ğ™˜ğ™š ğ™–ğ™¡ğ™¡ğ™¤ğ™˜ğ™–ğ™©ğ™ğ™¤ğ™£ ,ğ™ªğ™£ğ™ğ™šğ™–ğ™¡ğ™©ğ™ğ™® ğ™¥ğ™§ğ™¤ğ™˜ğ™šğ™¨ğ™¨ğ™šğ™¨

ğ™ğ™¨ğ™šğ™›ğ™ªğ™¡ ğ™˜ğ™¤ğ™¢ğ™¢ğ™–ğ™£ğ™™ğ™¨ 
 ```
 Kubectl logs <podname>
 ```
 ```
 Kubectl get po <podname> and check for its state 
 ```
Increase system resource usage


